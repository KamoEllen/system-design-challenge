#### **1. Introduction**
- **Topic**: Cache Write Strategies, focusing on how to handle writes in systems with caching layers.
- **Goal**: Understand the trade-offs between **write-around**, **write-through**, and **write-back** caching strategies.

---

#### **2. Distributed Cache Recap**
- **Benefits of Caching**:
  - Faster reads and writes due to faster storage (e.g., memory).
  - Reduced load on databases by serving repetitive requests from the cache.
- **Challenges**:
  - **Cache Misses**: Expensive due to additional network calls and cache searches.
  - **Data Consistency**: Ensuring the cache and database stay in sync is complex.

---

#### **3. Write-Around Cache**
- **Definition**: Writes bypass the cache and go directly to the database.
- **Process**:
  1. Write to the database.
  2. Option 1: **Stale Read** - Cache serves stale data until it expires (TTL).
  3. Option 2: **Invalidation** - Cache invalidates the key, forcing a cache miss on the next read.
- **Pros**:
  - Simple to implement.
  - Database remains the source of truth.
- **Cons**:
  - Cache misses are expensive.
  - Stale reads or additional invalidation steps are required for consistency.

---

#### **4. Write-Through Cache**
- **Definition**: Writes are simultaneously written to both the cache and the database.
- **Process**:
  1. Write to the cache.
  2. Write to the database.
- **Pros**:
  - Ensures data consistency between the cache and database.
  - Cache always has the latest data.
- **Cons**:
  - Slower writes due to dual writes.
  - **Two-Phase Commit**: Adds complexity and latency if used to ensure atomicity.

---

#### **5. Write-Back Cache**
- **Definition**: Writes are first written to the cache and later asynchronously written to the database.
- **Process**:
  1. Write to the cache.
  2. Batch writes to the database at a later time.
- **Pros**:
  - Fast writes since only the cache is updated initially.
  - Reduces load on the database by batching writes.
- **Cons**:
  - Risk of data loss if the cache fails before writing to the database.
  - Potential for stale reads if the database is not updated in time.
  - **Distributed Locking**: Can be used to ensure consistency but adds complexity and latency.

---

#### **6. Key Takeaways**
- **Write-Around Cache**:
  - Simple but leads to cache misses and stale reads.
  - Best for systems where writes are infrequent or consistency is less critical.
- **Write-Through Cache**:
  - Ensures consistency but slows down writes.
  - Ideal for systems where data consistency is critical.
- **Write-Back Cache**:
  - Fast writes but risks data loss and inconsistency.
  - Suitable for systems prioritizing write speed over immediate consistency.

---

#### **7. Conclusion**
- **Cache Write Strategies**:
  - Each strategy has distinct trade-offs in terms of speed, consistency, and complexity.
  - The choice depends on the applicationâ€™s requirements (e.g., speed vs. consistency).
- **Next Steps**:
  - Explore **cache eviction policies** to manage cache size and performance.
  - Dive deeper into **distributed locking** and **consistency models** for advanced caching scenarios.

